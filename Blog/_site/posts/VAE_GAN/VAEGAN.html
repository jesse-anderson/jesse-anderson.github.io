<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jesse Anderson">
<meta name="dcterms.date" content="2024-05-12">

<title>Jesse Anderson’s Blog - Generative Adventures: Exploring the Frontiers with VAEs, GANs, and VAE-GANs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-5CSPYCMY55"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-5CSPYCMY55', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Jesse Anderson’s Blog - Generative Adventures: Exploring the Frontiers with VAEs, GANs, and VAE-GANs">
<meta property="og:description" content="">
<meta property="og:image" content="VAEDifferentDigits.png">
<meta property="og:site_name" content="Jesse Anderson's Blog">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jesse Anderson’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html"> 
<span class="menu-text">Archive</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://jesse-anderson.github.io"> <i class="bi bi-Folder symlink fill" role="img">
</i> 
<span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jesse-anderson/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/jesse-anderson-a7c5/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Generative Adventures: Exploring the Frontiers with VAEs, GANs, and VAE-GANs</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ML</div>
                <div class="quarto-category">Generative AI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Jesse Anderson </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 12, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="generative-adventures-exploring-the-frontiers-with-vaes-gans-and-vae-gans" class="level1">
<h1>Generative Adventures: Exploring the Frontiers with VAEs, GANs, and VAE-GANs</h1>
<p>During my time in the applied machine learning course(CS441) at the University of Illinois at Urbana-Champaign, I embarked on an ambitious journey into the realm of advanced machine learning technologies. The course required a comprehensive understanding of various machine learning concepts, providing both breadth and depth in our studies. For my final optional project, I chose to specialize in some of the most intriguing areas of generative models: Variational AutoEncoders (VAEs), Denoising AutoEncoders, Generative Adversarial Networks (GANs), and the innovative hybrid, Variational Autoencoder Generative Adversarial Networks (VAE-GANs). Here, I provide a high-level overview of each technology and discuss the outcomes of my experiments. For further information about the course please see <a href="https://ws.engr.illinois.edu/sitemanager/getfile.asp?id=2218">sample syllabus</a>.</p>
<section id="variational-autoencoders-vaes" class="level3">
<h3 class="anchored" data-anchor-id="variational-autoencoders-vaes"><strong>Variational AutoEncoders (VAEs)</strong></h3>
<p>VAEs are powerful generative models that use the principles of probability and statistics to produce new data points that are similar to the training data. Unlike traditional autoencoders, which aim to compress and decompress data, VAEs introduce a probabilistic twist to encode input data into a distribution over latent space. This approach not only helps in generating new data but also improves the model’s robustness and the quality of generated samples. VAEs are particularly effective in tasks where you need a deep understanding of the data’s latent structure, such as in image generation and anomaly detection.</p>
<p>The encoder in a VAE is responsible for transforming high-dimensional input data into a lower-dimensional and more manageable representation. However, unlike standard autoencoders that directly encode data into a fixed point in latent space, the encoder in a VAE maps inputs into a distribution over the latent space. This distribution is typically parameterized by means (mu) and variances (sigma), which define a Gaussian probability distribution for each dimension in the latent space.</p>
<p>The latent space in VAEs is the core feature that distinguishes them from other types of autoencoders. It is a probabilistic space where each point is defined not just by coordinates, but by a distribution over possible values. This stochastic nature of the latent space allows VAEs to generate new data points by sampling from these distributions, providing a mechanism to capture and represent the underlying probabilistic properties of the data. It essentially acts as a compressed knowledge base of the data’s attributes.</p>
<p>Once a point in the latent space is sampled, the decoder part of the VAE takes over to map this probabilistic representation back to the original data space. The decoder learns to reconstruct the input data from its latent representation, aiming to minimize the difference between the original input and its reconstruction. This process is governed by a loss function that has two components: a reconstruction loss that measures how effectively the decoder reconstructs the input data from the latent space, and a regularization term that ensures the distribution characteristics in the latent space do not deviate significantly from a predefined prior (often a standard normal distribution).</p>
<p>In practice, the encoder’s output of means and variances provides a smooth and continuous latent space, which is crucial for generating new data points that are similar but not identical to the original data. This property makes VAEs particularly useful in tasks requiring a deep generative model, such as synthesizing new images that share characteristics with a training set, or identifying anomalies by seeing how well data points reconstruct using the learned distributions.</p>
<p><a href="VAE_Basic.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="VAE_Basic.png" class="img-fluid"></a></p>



    <title>Attribution Example</title>


    By <a href="//commons.wikimedia.org/wiki/User:EugenioTL" title="User:EugenioTL">EugenioTL</a> - Own work, <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons Attribution-Share Alike 4.0">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=107231101">Link</a>


</section>
<section id="denoising-autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="denoising-autoencoders"><strong>Denoising AutoEncoders</strong></h3>
<p>Denoising Autoencoders (DAEs) are specialized neural networks aimed at improving the quality of corrupted input data by learning to restore its original, uncorrupted state. This functionality is crucial in applications such as image restoration, where DAEs enhance image clarity by effectively removing noise. They achieve this through a training process that involves a dataset containing pairs of noisy and clean images. By continually adjusting through this training set, the DAE learns the underlying patterns necessary to filter out the distortions and recover the clean data. This ability to directly process and improve corrupted data makes DAEs valuable for various tasks beyond image restoration, including audio cleaning and improving data quality for analytical purposes.</p>
<p><a href="DAE_Image.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="DAE_Image.png" class="img-fluid"></a></p>
<p>Source: <a href="https://blog.keras.io/building-autoencoders-in-keras.html" class="uri">https://blog.keras.io/building-autoencoders-in-keras.html</a></p>
</section>
<section id="generative-adversarial-networks-gans" class="level3">
<h3 class="anchored" data-anchor-id="generative-adversarial-networks-gans"><strong>Generative Adversarial Networks (GANs)</strong></h3>
<p>Generative Adversarial Networks (GANs) utilize a unique framework involving two competing neural networks: a generator and a discriminator. These networks engage in an adversarial game, where the generator’s goal is to create synthetic data that is indistinguishable from real-world data, effectively “fooling” the discriminator. The discriminator’s job, on the other hand, is to distinguish between the authentic data and the synthetic creations of the generator.</p>
<p>This dynamic creates a feedback loop where the generator continually learns from the discriminator’s ability to detect fakes, driving it to improve its data generation. As the generator gets better, the discriminator’s task becomes more challenging, forcing it to improve its detection capabilities. Over time, this adversarial process leads to the generation of highly realistic and convincing data outputs.</p>
<p>GANs have been particularly successful in the field of image generation, where they are used to create highly realistic images that are often indistinguishable from actual photographs. A prominent example is the <a href="https://thispersondoesnotexist.com/"><strong>ThisPersonDoesNotExist</strong></a>website, which uses a model called <a href="https://github.com/NVlabs/stylegan2">StyleGAN2</a>to generate lifelike images of human faces that do not correspond to real individuals. This technology has also been applied in other areas such as art creation, style transfer, and more. Eerie.</p>
<p><a href="gan_diagram.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="gan_diagram.png" class="img-fluid"></a></p>
<p>Source: <a href="https://developers.google.com/machine-learning/gan/gan_structure" class="uri">https://developers.google.com/machine-learning/gan/gan_structure</a></p>
</section>
<section id="variational-autoencoder-generative-adversarial-networks-vae-gans" class="level3">
<h3 class="anchored" data-anchor-id="variational-autoencoder-generative-adversarial-networks-vae-gans"><strong>Variational Autoencoder Generative Adversarial Networks (VAE-GANs)</strong></h3>
<p>VAE-GANs are an innovative hybrid model that synergistically combines Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to enhance the quality and control of data generation. The model integrates the VAE’s capability for creating a compressed, latent representation of data with the GAN’s strength in generating high-fidelity outputs.</p>
<p>In a VAE-GAN system, the encoder part of the VAE compresses input data into a latent space (a condensed representation), which the GAN’s generator then uses to reconstruct outputs that are as realistic as possible. This setup leverages the VAE’s ability to manage and interpret the latent space effectively, providing a structured, meaningful input for the GAN’s generator. The discriminator in the GAN setup then evaluates these outputs against real data, guiding the generator to improve its outputs continually.</p>
<p>The fusion of these two models allows for a more controlled generation process, which can lead to higher quality outputs than what might be achieved by either model alone. This approach not only enhances the detail and realism of the generated data but also improves the model’s ability to learn diverse and complex data distributions, making VAE-GANs particularly useful in tasks that require a high level of detail and accuracy, such as in image generation and modification.</p>
<p><a href="VAE_GAN_Diagram.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="VAE_GAN_Diagram.png" class="img-fluid"></a></p>
<p>Source: Larsen, Anders &amp; Sønderby, Søren &amp; Winther, Ole. (2015). Autoencoding beyond pixels using a learned similarity metric.</p>
</section>
<section id="project-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="project-outcomes"><strong>Project Outcomes</strong></h3>
<p>The practical application of these models in my project yielded fascinating insights and results. For instance, the VAEs demonstrated an impressive ability to generate new images that closely resembled the original dataset, while the Denoising AutoEncoders more or less restored a significant portion of corrupted images to their original state. Similarly, the GANs produced images that were often indistinguishable from real ones, highlighting their potential in creating synthetic data for training other machine learning models without the need for extensive real-world data collection.</p>
<p>The VAE-GANs, however, were the highlight, combining the best aspects of their constituent models to generate supremely realistic and diverse outputs. While I am unable to share specific code snippets of the DAE/VAE due to copyright restrictions on the course content, the qualitative outcomes were highly encouraging and indicative of the powerful capabilities of hybrid generative models.</p>
</section>
<section id="results" class="level3">
<h3 class="anchored" data-anchor-id="results">Results</h3>
</section>
<section id="denoising-autoencoder" class="level3">
<h3 class="anchored" data-anchor-id="denoising-autoencoder">Denoising AutoEncoder</h3>
<p><a href="DAEBeforeAndAfter.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="DAEBeforeAndAfter.png" class="img-fluid"></a></p>
<p>As you can see in the image above, it does an ok job of denoising the middle image. The top image is the original image, the middle is the image with 50% noise, and the bottom is the model’s outputted denoised image. If I trained the model longer and varied up the training data I likely would have been able to get a better result. Additionally Principal Component Analysis and calculation of the Mean Residual Error was performed to determine how well the model works. See below:</p>
<p><a href="DAE_PCA_Analysis.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="DAE_PCA_Analysis.png" class="img-fluid"></a></p>
<p>Loss over Epochs(Note the plots say reconstruction error when I really meant Mean Squared Error Loss):</p>
<p><a href="DAE_Losses.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="DAE_Losses.png" class="img-fluid"></a></p>
<p>I decided to use a standard fixed learning rate here and only trained for 240 epochs.</p>
</section>
<section id="variational-autoencoder" class="level3">
<h3 class="anchored" data-anchor-id="variational-autoencoder">Variational AutoEncoder</h3>
<p>Here we were tasked with coming up with a VAE which would generate images and also be able to interpolate between images.</p>
<p>Same Digits:</p>
<p><a href="VAESameDigits.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="VAESameDigits.png" class="img-fluid"></a></p>
<p>Different Digits:</p>
<p><a href="VAEDifferentDigits.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="VAEDifferentDigits.png" class="img-fluid"></a></p>
<p>Original vs.&nbsp;Reconstructed:</p>
<p><a href="VAEOriginalVsReconstructed.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="VAEOriginalVsReconstructed.png" class="img-fluid"></a></p>
<p>As you can see the VAE did a fairly good job of generating images.</p>
<p>Loss over 400 Epochs:</p>
<p><a href="VAE_Losses.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="VAE_Losses.png" class="img-fluid"></a></p>
<p>I was playing around with progressively reducing the learning rate as parameters changed(or didn’t) and thus reduced the learning rate progressively. This actually seemed to result in the exponentialLR type scheduler funnily enough. See <a href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html">here</a>. The model was trained for 400 epochs. I likely won’t spin the DAE/VAE back up for videos as I did for the GAN and VAE-GAN.</p>
</section>
<section id="generative-adversarial-network" class="level3">
<h3 class="anchored" data-anchor-id="generative-adversarial-network">Generative Adversarial Network</h3>
<p>I decided to go a bit further and try to get a Generative Adversarial Network running to generate new images of numbers. I went beyond the standard requirements of the course, but not too far as I didn’t want to “waste” too much time as there are newer technologies nowadays. <a href="https://github.com/jesse-anderson/GAN-MNIST-PyTorch/tree/main">Here’s the repo</a>. There is a video below that shows the evolution of the training of the model. Additionally here’s the final result and video below:</p>
<p><a href="GANOutput.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="GANOutput.png" class="img-fluid"></a></p>



<meta charset="UTF-8">
<style>
  video {
    max-width: 90%; /* Adjust width as necessary */
    max-height: 90%; /* Adjust height as necessary */
  }
  </style>



<h1>Click to Play Video</h1>

<!-- Video container -->
<video id="myVideo1" controls="">
  <source id="videoSource1" src="../../posts/VAE_GAN/MNIST_GAN_Training.mp4" type="video/mp4">
  Your browser does not support MP4 videos.
</video>
<!-- Button to load and play the video -->
<button onclick="loadAndPlayVideo(myVideo1'../../posts/VAE_GAN/MNIST_GAN_Training.mp4')">Load and Play Video</button>

<script>
  function loadAndPlayVideo(videoId, src) {
    var video = document.getElementById(videoId);
    var source = video.getElementsByTagName('source')[0];
    source.src = src;
    video.load(); // Load the new video source
    video.style.display = "block"; // Make the video visible
    video.play(); // Play the video
  }
</script>



<p>Losses over 540 Epochs:</p>
<p><a href="GANLosses540Epoch.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="GANLosses540Epoch.png" class="img-fluid"></a></p>
</section>
<section id="vae-gan" class="level3">
<h3 class="anchored" data-anchor-id="vae-gan">VAE-GAN</h3>
<p>I finally went a bit further(probably too far) and decided to implement a VAE-GAN. There was a lot more balancing involved between the autoencoder portion and the generative portion and I was able to achieve a passable result, but definitely not worth the time and effort to balance parameters. It was strangely smoothed out, yet blurred where it mattered to generate the images.</p>
<p>Final result image and video below:</p>
<p><a href="VAE_GANOutput.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="VAE_GANOutput.png" class="img-fluid"></a></p>



<meta charset="UTF-8">
<style>
  video {
    max-width: 90%; /* Adjust width as necessary */
    max-height: 90%; /* Adjust height as necessary */
  }
  </style>



<h1>Click to Play Video</h1>

<!-- Video container -->
<video id="myVideo2" controls="">
  <source id="videoSource2" src="../../posts/VAE_GAN/MNIST_VAE_GAN_Training.mp4" type="video/mp4">
  Your browser does not support MP4 videos.
</video>

<!-- Button to load and play the video -->
<button onclick="loadAndPlayVideo(myVideo2,'../../posts/VAE_GAN/MNIST_VAE_GAN_Training.mp4')">Load and Play Video</button>

<script>
  function loadAndPlayVideo(videoId,src) {
    var video = document.getElementById(videoId);
    var source = video.getElementsByTagName('source')[0];
    source.src = src;
    video.load(); // Load the new video source
    video.style.display = "block"; // Make the video visible
    video.play(); // Play the video
  }
</script>



<p>Here’s the associated Losses over 1000 Epochs(note my discriminator freaking out…):</p>
<p><a href="VAEGanLosses1000epochs.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="VAEGanLosses1000epochs.png" class="img-fluid"></a></p>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts"><strong>Final Thoughts</strong></h3>
<p>Exploring these advanced generative models not only enhanced my understanding of the deep theoretical underpinnings of machine learning but also provided a practical toolkit for addressing complex real-world data generation and enhancement challenges. The knowledge and experience gained through this project are invaluable and have opened up numerous possibilities for further research and application in the field of artificial intelligence. I anticipate broadening my skillset in Generative AI here soon and will continue to skill up. I also got to experience the sheer tedium of “untangling” a neural network wherein something went wrong in my layers… repeatedly.</p>


</section>
</section>

</main> <!-- /main -->
<!--  General footer to put at bottom of page.   -->





    <meta charset="UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Support Page</title>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

    <style>

        .centered-text {

            text-align: center; /* Centers text for elements with this class */

        }

      .centered-content {

          display: flex; /* Uses Flexbox for layout */

          justify-content: center; /* Horizontally centers the content within the container */

          vertical-align: middle;

      }

      .email-share-button {

          background: #007BFF; /* Example: a distinct blue color for the email button */

          color: white; /* Ensure text and icon are white for visibility */

      }



  </style>



<footer class="centered-text">

    <p>Copyright © <span id="copyright-year"></span> Jesse Anderson</p>

    <!-- Other footer details -->

  </footer>

<div>

    <hr>

    <h3 class="centered-text"> Support my work with a Coffee/Monster </h3>

<div class="centered-content">

  <script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="jesseanderson" data-color="#06436e" data-emoji="☕" data-font="Lato" data-text="Support me" data-outline-color="#ffffff" data-font-color="#ffffff" data-coffee-color="#FFDD00" data-height="40px"></script>

</div>

<!-- Footer content -->



<p></p><h3 class="centered-text">Share</h3><p></p>

  <!-- Share Buttons -->

  <div id="share-buttons" class="centered-content">

 



      <!-- Twitter Share Button, dynamically setting the URL -->

      <a href="#" class="share-button twitter-share-button" data-size="large" data-hashtags="computerscience" data-via="JesseA7C5" data-show-count="false">Tweet</a>

      <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  

      <!-- Facebook SDK with Dynamic Nonce -->

      <div id="fb-root"></div>

      <script id="facebook-jssdk" async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v10.0"></script>

      <div class="fb-share-button share-button" data-href="" data-layout="button_count">

      </div>

  

      <!-- LinkedIn Share Button -->

    <!-- LinkedIn Share Button -->

    <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>

    <script type="IN/Share" data-url=""></script>

    <!-- Email Share Button -->

    <a href="#" class="share-button email-share-button"><i class="fas fa-envelope"></i></a>

    </div>

  </div>

  

  <script>

    // Function to generate a random nonce

    function generateNonce(length = 16) {

      const possible = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";

      let text = "";

      for (let i = 0; i < length; i++) {

        text += possible.charAt(Math.floor(Math.random() * possible.length));

      }

      return text;

    }

  

    // Set the nonce attribute for the Facebook SDK script and dynamically set URLs

    document.addEventListener('DOMContentLoaded', function() {

      const nonce = generateNonce();

      const facebookSDKScript = document.getElementById('facebook-jssdk');

      facebookSDKScript.setAttribute('nonce', nonce);

      var elems = document.querySelectorAll('script[type="IN/Share"]');

        for (var i = 0; i < elems.length; i++) {

            elems[i].setAttribute('data-url', window.location.href);

        }



      // Set dynamic URLs for social sharing

      const currentUrl = window.location.href;

      const currentTitle = document.title; // Use the current document title as the email subject

      //Facebook

      document.querySelector('.fb-share-button').setAttribute('data-href', currentUrl);

      //LinkedIn

      document.querySelectorAll('script[type="IN/Share"]')[0].setAttribute('data-url', currentUrl);

      //Twitter

      document.querySelector('.twitter-share-button').setAttribute('href', 'https://twitter.com/share?url=' + encodeURIComponent(currentUrl) + '&hashtags=rstats');

      // Email

      document.querySelector('.email-share-button').setAttribute('href', `mailto:?subject=${encodeURIComponent(currentTitle)}&body=Check out this link: ${encodeURIComponent(currentUrl)}`);

      // Dynamically set the current year in the copyright footer

      document.getElementById('copyright-year').textContent = new Date().getFullYear();

    });

  </script>

  

  <style>

      #share-buttons {

          display: flex;

          align-items: center;

          justify-content: center;

          gap: 5px;

      }

  

      .share-button {

          display: inline-flex;

          padding: 2px 4px;

          font-size: 14px;

          cursor: pointer;

          text-align: center;

          color: white;

          border-radius: 0px;

      }

  

  </style>


<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="jesse-anderson/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"descPosition":"bottom","loop":false,"selector":".lightbox","closeEffect":"zoom","openEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




</body></html>